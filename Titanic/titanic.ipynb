{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "29.69911764705882\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv')\n",
    "#print(data)\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "avg = data['Age'].mean()\n",
    "print(avg)\n",
    "em = data['Embarked'].mode()\n",
    "\n",
    "\n",
    "data['Age'].fillna(value=30, inplace=True)\n",
    "data['Embarked'].fillna(value='S', inplace=True)\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=({'PassengerId': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Pclass': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Name': TensorSpec(shape=(), dtype=tf.string, name=None), 'Sex': TensorSpec(shape=(), dtype=tf.string, name=None), 'Age': TensorSpec(shape=(), dtype=tf.float64, name=None), 'SibSp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Parch': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Ticket': TensorSpec(shape=(), dtype=tf.string, name=None), 'Fare': TensorSpec(shape=(), dtype=tf.float64, name=None), 'Embarked': TensorSpec(shape=(), dtype=tf.string, name=None)}, TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "result = data.pop('Survived')\n",
    "\n",
    "# 데이터 셋 만들기 (X데이터, 정답)\n",
    "ds = tf.data.Dataset.from_tensor_slices((dict(data), result))\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nomalizer(x):\n",
    "    mini = data['Fare'].min()\n",
    "    maxi = data['Fare'].max()\n",
    "    return (x-mini) / (maxi - mini)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "[NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SibSp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(10, 20, 30, 40, 50, 60))]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# 숫자로 집어넣어야 하는 것 Fare Parch SibSp : numeric_column\n",
    "# 뭉퉁그려서 집어넣을 것 Age : bucketized_column\n",
    "# 종류 몇개없는 카테고리화해서 접어넣어야 하는 것 Sex Embarked Pclass : indicator_column\n",
    "# 종류가 많은 카테고리 Ticket : embedding_column\n",
    "\n",
    "feature_columns.append(tf.feature_column.numeric_column('Fare'))\n",
    "feature_columns.append(tf.feature_column.numeric_column('Parch'))\n",
    "feature_columns.append(tf.feature_column.numeric_column('SibSp'))\n",
    "# feature_columns.append(tf.feature_column.numeric_column('Age'))\n",
    "\n",
    "Age = tf.feature_column.numeric_column('Age')\n",
    "Age_bucket = tf.feature_column.bucketized_column(Age, boundaries=[10,20,30,40,50,60])\n",
    "feature_columns.append(Age_bucket)\n",
    "\n",
    "print(Age)\n",
    "print(feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼에 있는 유니크한 리스트\n",
    "vocab = data['Sex'].unique()\n",
    "\n",
    "# 원 핫 인코등\n",
    "cate = tf.feature_column.categorical_column_with_vocabulary_list('Sex',vocab )\n",
    "# print(vocab)\n",
    "one_hot = tf.feature_column.indicator_column(cate)\n",
    "feature_columns.append(one_hot)\n",
    "\n",
    "# 컬럼에 있는 유니크한 리스트\n",
    "vocab = data['Embarked'].unique()\n",
    "# 원 핫 인코등\n",
    "cate = tf.feature_column.categorical_column_with_vocabulary_list('Embarked',vocab )\n",
    "# print(vocab)\n",
    "one_hot = tf.feature_column.indicator_column(cate)\n",
    "feature_columns.append(one_hot)\n",
    "\n",
    "# 컬럼에 있는 유니크한 리스트\n",
    "vocab = data['Pclass'].unique()\n",
    "# 원 핫 인코등\n",
    "cate = tf.feature_column.categorical_column_with_vocabulary_list('Pclass',vocab )\n",
    "# print(vocab)\n",
    "one_hot = tf.feature_column.indicator_column(cate)\n",
    "feature_columns.append(one_hot)\n",
    "\n",
    "# embedding\n",
    "vocab = data['Ticket'].unique()\n",
    "# 원 핫 인코등\n",
    "cate = tf.feature_column.categorical_column_with_vocabulary_list('Ticket',vocab )\n",
    "# print(vocab)\n",
    "embedding = tf.feature_column.embedding_column(cate, dimension=9)\n",
    "feature_columns.append(embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=({'PassengerId': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Pclass': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Name': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Sex': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Age': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'SibSp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Parch': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Ticket': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Fare': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Embarked': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n",
      "[NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SibSp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(10, 20, 30, 40, 50, 60)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Embarked', vocabulary_list=('S', 'C', 'Q'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Pclass', vocabulary_list=(3, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='Ticket', vocabulary_list=('A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450', '330877', '17463', '349909', '347742', '237736', 'PP 9549', '113783', 'A/5. 2151', '347082', '350406', '248706', '382652', '244373', '345763', '2649', '239865', '248698', '330923', '113788', '347077', '2631', '19950', '330959', '349216', 'PC 17601', 'PC 17569', '335677', 'C.A. 24579', 'PC 17604', '113789', '2677', 'A./5. 2152', '345764', '2651', '7546', '11668', '349253', 'SC/Paris 2123', '330958', 'S.C./A.4. 23567', '370371', '14311', '2662', '349237', '3101295', 'A/4. 39886', 'PC 17572', '2926', '113509', '19947', 'C.A. 31026', '2697', 'C.A. 34651', 'CA 2144', '2669', '113572', '36973', '347088', 'PC 17605', '2661', 'C.A. 29395', 'S.P. 3464', '3101281', '315151', 'C.A. 33111', 'S.O.C. 14879', '2680', '1601', '348123', '349208', '374746', '248738', '364516', '345767', '345779', '330932', '113059', 'SO/C 14885', '3101278', 'W./C. 6608', 'SOTON/OQ 392086', '343275', '343276', '347466', 'W.E.P. 5734', 'C.A. 2315', '364500', '374910', 'PC 17754', 'PC 17759', '231919', '244367', '349245', '349215', '35281', '7540', '3101276', '349207', '343120', '312991', '349249', '371110', '110465', '2665', '324669', '4136', '2627', 'STON/O 2. 3101294', '370369', 'PC 17558', 'A4. 54510', '27267', '370372', 'C 17369', '2668', '347061', '349241', 'SOTON/O.Q. 3101307', 'A/5. 3337', '228414', 'C.A. 29178', 'SC/PARIS 2133', '11752', '7534', 'PC 17593', '2678', '347081', 'STON/O2. 3101279', '365222', '231945', 'C.A. 33112', '350043', '230080', '244310', 'S.O.P. 1166', '113776', 'A.5. 11206', 'A/5. 851', 'Fa 265302', 'PC 17597', '35851', 'SOTON/OQ 392090', '315037', 'CA. 2343', '371362', 'C.A. 33595', '347068', '315093', '363291', '113505', 'PC 17318', '111240', 'STON/O 2. 3101280', '17764', '350404', '4133', 'PC 17595', '250653', 'LINE', 'SC/PARIS 2131', '230136', '315153', '113767', '370365', '111428', '364849', '349247', '234604', '28424', '350046', 'PC 17610', '368703', '4579', '370370', '248747', '345770', '3101264', '2628', 'A/5 3540', '347054', '2699', '367231', '112277', 'SOTON/O.Q. 3101311', 'F.C.C. 13528', 'A/5 21174', '250646', '367229', '35273', 'STON/O2. 3101283', '243847', '11813', 'W/C 14208', 'SOTON/OQ 392089', '220367', '21440', '349234', '19943', 'PP 4348', 'SW/PP 751', 'A/5 21173', '236171', '347067', '237442', 'C.A. 29566', 'W./C. 6609', '26707', 'C.A. 31921', '28665', 'SCO/W 1585', '367230', 'W./C. 14263', 'STON/O 2. 3101275', '2694', '19928', '347071', '250649', '11751', '244252', '362316', '113514', 'A/5. 3336', '370129', '2650', 'PC 17585', '110152', 'PC 17755', '230433', '384461', '110413', '112059', '382649', 'C.A. 17248', '347083', 'PC 17582', 'PC 17760', '113798', '250644', 'PC 17596', '370375', '13502', '347073', '239853', 'C.A. 2673', '336439', '347464', '345778', 'A/5. 10482', '113056', '349239', '345774', '349206', '237798', '370373', '19877', '11967', 'SC/Paris 2163', '349236', '349233', 'PC 17612', '2693', '113781', '19988', '9234', '367226', '226593', 'A/5 2466', '17421', 'PC 17758', 'P/PP 3381', 'PC 17485', '11767', 'PC 17608', '250651', '349243', 'F.C.C. 13529', '347470', '29011', '36928', '16966', 'A/5 21172', '349219', '234818', '345364', '28551', '111361', '113043', 'PC 17611', '349225', '7598', '113784', '248740', '244361', '229236', '248733', '31418', '386525', 'C.A. 37671', '315088', '7267', '113510', '2695', '2647', '345783', '237671', '330931', '330980', 'SC/PARIS 2167', '2691', 'SOTON/O.Q. 3101310', 'C 7076', '110813', '2626', '14313', 'PC 17477', '11765', '3101267', '323951', 'C 7077', '113503', '2648', '347069', 'PC 17757', '2653', 'STON/O 2. 3101293', '349227', '27849', '367655', 'SC 1748', '113760', '350034', '3101277', '350052', '350407', '28403', '244278', '240929', 'STON/O 2. 3101289', '341826', '4137', '315096', '28664', '347064', '29106', '312992', '349222', '394140', 'STON/O 2. 3101269', '343095', '28220', '250652', '28228', '345773', '349254', 'A/5. 13032', '315082', '347080', 'A/4. 34244', '2003', '250655', '364851', 'SOTON/O.Q. 392078', '110564', '376564', 'SC/AH 3085', 'STON/O 2. 3101274', '13507', 'C.A. 18723', '345769', '347076', '230434', '65306', '33638', '113794', '2666', '113786', '65303', '113051', '17453', 'A/5 2817', '349240', '13509', '17464', 'F.C.C. 13531', '371060', '19952', '364506', '111320', '234360', 'A/S 2816', 'SOTON/O.Q. 3101306', '113792', '36209', '323592', '315089', 'SC/AH Basle 541', '7553', '31027', '3460', '350060', '3101298', '239854', 'A/5 3594', '4134', '11771', 'A.5. 18509', '65304', 'SOTON/OQ 3101317', '113787', 'PC 17609', 'A/4 45380', '36947', 'C.A. 6212', '350035', '315086', '364846', '330909', '4135', '26360', '111427', 'C 4001', '382651', 'SOTON/OQ 3101316', 'PC 17473', 'PC 17603', '349209', '36967', 'C.A. 34260', '226875', '349242', '12749', '349252', '2624', '2700', '367232', 'W./C. 14258', 'PC 17483', '3101296', '29104', '2641', '2690', '315084', '113050', 'PC 17761', '364498', '13568', 'WE/P 5735', '2908', '693', 'SC/PARIS 2146', '244358', '330979', '2620', '347085', '113807', '11755', '345572', '372622', '349251', '218629', 'SOTON/OQ 392082', 'SOTON/O.Q. 392087', 'A/4 48871', '349205', '2686', '350417', 'S.W./PP 752', '11769', 'PC 17474', '14312', 'A/4. 20589', '358585', '243880', '2689', 'STON/O 2. 3101286', '237789', '13049', '3411', '237565', '13567', '14973', 'A./5. 3235', 'STON/O 2. 3101273', 'A/5 3902', '364848', 'SC/AH 29037', '248727', '2664', '349214', '113796', '364511', '111426', '349910', '349246', '113804', 'SOTON/O.Q. 3101305', '370377', '364512', '220845', '31028', '2659', '11753', '350029', '54636', '36963', '219533', '349224', '334912', '27042', '347743', '13214', '112052', '237668', 'STON/O 2. 3101292', '350050', '349231', '13213', 'S.O./P.P. 751', 'CA. 2314', '349221', '8475', '330919', '365226', '349223', '29751', '2623', '5727', '349210', 'STON/O 2. 3101285', '234686', '312993', 'A/5 3536', '19996', '29750', 'F.C. 12750', 'C.A. 24580', '244270', '239856', '349912', '342826', '4138', '330935', '6563', '349228', '350036', '24160', '17474', '349256', '2672', '113800', '248731', '363592', '35852', '348121', 'PC 17475', '36864', '350025', '223596', 'PC 17476', 'PC 17482', '113028', '7545', '250647', '348124', '34218', '36568', '347062', '350048', '12233', '250643', '113806', '315094', '36866', '236853', 'STON/O2. 3101271', '239855', '28425', '233639', '349201', '349218', '16988', '376566', 'STON/O 2. 3101288', '250648', '113773', '335097', '29103', '392096', '345780', '349204', '350042', '29108', '363294', 'SOTON/O2 3101272', '2663', '347074', '112379', '364850', '8471', '345781', '350047', 'S.O./P.P. 3', '2674', '29105', '347078', '383121', '36865', '2687', '113501', 'W./C. 6607', 'SOTON/O.Q. 3101312', '374887', '3101265', '12460', 'PC 17600', '349203', '28213', '17465', '349244', '2685', '2625', '347089', '347063', '112050', '347087', '248723', '3474', '28206', '364499', '112058', 'STON/O2. 3101290', 'S.C./PARIS 2079', 'C 7075', '315098', '19972', '368323', '367228', '2671', '347468', '2223', 'PC 17756', '315097', '392092', '11774', 'SOTON/O2 3101287', '2683', '315090', 'C.A. 5547', '349213', '347060', 'PC 17592', '392091', '113055', '2629', '350026', '28134', '17466', '233866', '236852', 'SC/PARIS 2149', 'PC 17590', '345777', '349248', '695', '345765', '2667', '349212', '349217', '349257', '7552', 'C.A./SOTON 34068', 'SOTON/OQ 392076', '211536', '112053', '111369', '370376'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=9, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000022F7DC5A5E0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True)]\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 946us/step - loss: 1.3117 - acc: 0.5612\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.9580 - acc: 0.6633\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.7826 - acc: 0.7104\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.6631 - acc: 0.7239\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.6518 - acc: 0.7441\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.6667 - acc: 0.7621\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.5292 - acc: 0.7946\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.4666 - acc: 0.8137\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.4593 - acc: 0.8182\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.4180 - acc: 0.8316\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.3841 - acc: 0.8429\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3644 - acc: 0.8530\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.4112 - acc: 0.8474\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.2873 - acc: 0.8754\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.3172 - acc: 0.8844\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.4821 - acc: 0.8687\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.2475 - acc: 0.9035\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.2095 - acc: 0.9169\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.2065 - acc: 0.9304\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1668 - acc: 0.9450\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1364 - acc: 0.9540\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1322 - acc: 0.9630\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.1013 - acc: 0.9663\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0868 - acc: 0.9708\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1007 - acc: 0.9675\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0905 - acc: 0.9764\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.1209 - acc: 0.9663\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0534 - acc: 0.9843\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0820 - acc: 0.9787\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0743 - acc: 0.9753\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0621 - acc: 0.9809\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0437 - acc: 0.9865\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0426 - acc: 0.9843\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0366 - acc: 0.9888\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0812 - acc: 0.9776\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0356 - acc: 0.9877\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0338 - acc: 0.9899\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0368 - acc: 0.9877\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0341 - acc: 0.9910\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0527 - acc: 0.9843\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0305 - acc: 0.9899\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0336 - acc: 0.9910\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0321 - acc: 0.9888\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0312 - acc: 0.9888\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0283 - acc: 0.9865\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0272 - acc: 0.9877\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0329 - acc: 0.9854\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0268 - acc: 0.9910\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0271 - acc: 0.9910\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0223 - acc: 0.9899\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0220 - acc: 0.9877\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0211 - acc: 0.9910\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0212 - acc: 0.9933\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0308 - acc: 0.9854\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0228 - acc: 0.9910\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0258 - acc: 0.9910\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0443 - acc: 0.9832\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0245 - acc: 0.9921\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0218 - acc: 0.9910\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0186 - acc: 0.9910\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0250 - acc: 0.9921\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0241 - acc: 0.9877\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0523 - acc: 0.9832\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0171 - acc: 0.9899\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0209 - acc: 0.9910\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0245 - acc: 0.9910\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0193 - acc: 0.9933\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0233 - acc: 0.9877\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0251 - acc: 0.9910\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0188 - acc: 0.9888\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0293 - acc: 0.9888\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0173 - acc: 0.9921\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0228 - acc: 0.9865\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0205 - acc: 0.9921\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0303 - acc: 0.9877\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0170 - acc: 0.9933\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0204 - acc: 0.9921\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0235 - acc: 0.9910\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0162 - acc: 0.9921\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0177 - acc: 0.9921\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0509 - acc: 0.9832\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0414 - acc: 0.9888\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0308 - acc: 0.9899\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0312 - acc: 0.9877\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0204 - acc: 0.9877\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0233 - acc: 0.9899\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0177 - acc: 0.9921\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0199 - acc: 0.9888\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0181 - acc: 0.9899\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0174 - acc: 0.9910\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0225 - acc: 0.9888\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0172 - acc: 0.9944\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0185 - acc: 0.9921\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0184 - acc: 0.9921\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0212 - acc: 0.9910\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0162 - acc: 0.9933\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0187 - acc: 0.9921\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0176 - acc: 0.9955\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0217 - acc: 0.9865\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0241 - acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22f7db41a90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "ds_batch = ds.batch(32)\n",
    "print(ds_batch)\n",
    "print(feature_columns)\n",
    "model.fit(ds_batch, shuffle=True, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
